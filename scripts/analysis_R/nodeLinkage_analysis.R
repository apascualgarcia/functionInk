############################
#   nodeLinkage_analysis.R
############################
#
# This script takes the compact History file generated by nodeLinkage.pl
# and extracts the maximum values for the partition densities measures, together
# with a summary plot
############################
# USAGE: Bring the history file in the variable file.hist.
# OUTPUT: The step at which the partition densities are maximum, and a summary plot of the partition densities.
############################

library(ggplot2)

Set="M10"
# --- Load the history compact file (NodeLinkage output)
#dir="/home/apascual/APASCUAL/Research/Projects/Simons/Meetings/ETH_April19/Analysis"
#dir="/home/apascual/Nextcloud/Research/Projects/FunctionalLinkage/SoniaKefi/NodeLinkage/"# NetsExhaustClustering" #"SoniaKefi/NodeLinkage/"
#dir="/home/apascual/Nextcloud/Research/Projects/FunctionalGroups/InteractionInference/TaxonsTime0/Networks"
#dir="/home/apascual/Nextcloud/Research/Projects/Ramoneda_Antarctica/SparCC"
dir=paste("/home/apascual/Nextcloud/Research/Projects/Bittleston/SparCC/",Set,"/functionInk",sep="")
setwd(dir)

# Set the input file and label for the output file
#label="Nest0.6_Conn0.08_CompConn0" # Include a label for the output file
#label="KefiNetwork"
#label="Simons_Keywords"
label=Set
#file.hist="HistCompact-NL_Average_NoStop_NetworkOfFeatures_People_in.txt"
#file.hist="HistCompact-NL_Average_NoStop_Network_chilean_merged.tsv"
#file.hist="HistCompact-NL_Average_NoStop_Network-CorSparCC_7days.clean.matched.transp.replica1.Taxa.pval0.01_cor0.3.txt"
#file.hist="HistCompact-NL_Average_NoStop_Network-CorSparCC_Time0.pval0.01_cor0.2.tsv"
#file.hist=paste("HistCompact-NL_Average_NoStop_Rmrz89_Exhaust_",label,".long.txt",sep="")
#file.hist="HistCompact-NL_Average_NoStop_Network_BasisCor_SparCC_GT0.8.txt"
file.hist=paste("HistCompact-NL_Average_NoStop_Network-CorSparCC_",Set,".cor-0.4.pval0.001.tsv",sep="")

# ---- STOP EDITING HERE 

hist.comp=read.table(file=file.hist,sep="\t",header = TRUE) # for current NodeLink.pl version (Dec 2018)
#hist.comp=read.table(file=file.hist,sep=" ",header = FALSE) # For old results
#colnames(hist.comp)=c("Step","maxGlobalTmp","Density","DensityInt","DensityExt","NumNodesA","NumEdgesA",
#       "NumNodesB","NumEdgesB","NumNodesAB","NumEdgesAB","NumIntNodesA","NumIntNodesB","NumExtNodesA",
#       "NumExtNodesB","NumIntNodesAB","NumExtNodesAB","NumIntEdgesA","NumIntEdgesB","NumExtEdgesA",
#      "NumExtEdgesB","NumIntEdgesAB","NumExtEdgesAB","nodeA","nodeB","NcumInt","NcumExt","Ncum") # for old results

# --- Plot
system(command="mkdir -p figures")
setwd("figures")
fileOut=paste("Plot_PartitionDensityVsStep_",label,".pdf",sep="")
pdf(file=fileOut,width=10,height=8)
print(ggplot(data = hist.comp) + 
  geom_point(mapping = aes(x=Step,y=Density,color="Total"))+
  geom_point(mapping = aes(x=Step,y=DensityInt,color="Internal"),shape=2)+
  geom_point(mapping = aes(x=Step,y=DensityExt,color="External"),shape=6) + 
  geom_line(mapping = aes(x=Step,y=Density,color="Total"))+
  geom_line(mapping = aes(x=Step,y=DensityInt,color="Internal"))+
  geom_line(mapping = aes(x=Step,y=DensityExt,color="External"))+
  xlab("Clustering Step")+
  theme(legend.title =  element_blank(),
        axis.text = element_text(size=20),axis.title = element_text(size=24),
        legend.text =element_text(size=18)))
dev.off()

# --- Retrieve maximumu and report
maxDens=hist.comp$Step[which.max(hist.comp$Density)]
maxDensExt=hist.comp$Step[which.max(hist.comp$DensityExt)]
maxDensInt=hist.comp$Step[which.max(hist.comp$DensityInt)]

print("Maximum total partition density found at step =")
print(maxDens,digits=3)
print("Maximum external partition density found at step =")
print(maxDensExt,digits=3)
print("Maximum internal partition density found at step =")
print(maxDensInt,digits=3)

